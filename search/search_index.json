{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"CruiseKube <p>Intelligent Kubernetes Optimization</p> <p>       Automatically monitor, analyze, and optimize your Kubernetes workloads for maximum efficiency and cost savings.     </p> Get Started Join our community Why CruiseKube? <p>Streamline your Kubernetes operations with intelligent automation</p>          \u2699\ufe0f        Automated Optimization <p>Continuously monitors workload patterns and applies intelligent resource recommendations</p>          \ud83d\udcb0        Cost Reduction <p>Reduce infrastructure costs by up to 40% through intelligent resource right-sizing</p>          \ud83d\udd12        Safe Operations <p>Built-in safeguards and dry-run modes ensure your workloads remain stable</p> How It Works <p>Simple, automated optimization in four steps</p> 01 Monitor <p>Continuously collects metrics from Prometheus and analyzes workload patterns</p> 02 Recommend <p>Generates intelligent resource recommendations based on historical data</p> 03 Optimize <p>Safely applies recommendations with configurable automation levels</p> Join Our Community <p>Get help, share your experience, and contribute to CruiseKube</p>          \ud83d\udc31        GitHub          \ud83d\udcac        Discord          \ud83d\udc1b        Report Issues Ready to optimize your Kubernetes cluster? <p>Start saving costs and improving performance today</p> Get Started Now"},{"location":"blog/2026/01/12/introducing-cruisekube---runtime-resource-optimization-for-kubernetes/","title":"Introducing CruiseKube - Runtime Resource Optimization for Kubernetes","text":"<p>Today, we\u2019re excited to announce the release of CruiseKube - a runtime resource optimization engine for Kubernetes that continuously right-sizes pods without restarts, unlocking significant cost efficiency gains while preserving reliability.</p>"},{"location":"blog/2026/01/12/introducing-cruisekube---runtime-resource-optimization-for-kubernetes/#what-is-cruisekube","title":"What is CruiseKube?","text":"<p>CruiseKube is a Kubernetes-native, continuous resource optimization system that autonomously right-sizes CPU and memory for workloads at runtime and admission time. It focuses on eliminating persistent over-provisioning while preserving workload reliability and scheduling constraints.</p> <p>Unlike static requests, manual tuning, or reactive autoscaling, CruiseKube operates as a closed-loop control system that observes real workload behavior and incrementally converges resource requests toward optimal values.</p>"},{"location":"blog/2026/01/12/introducing-cruisekube---runtime-resource-optimization-for-kubernetes/#when-do-you-need-cruisekube","title":"When do you need CruiseKube?","text":"<p>You would need CruiseKube if you are facing any of these issues -</p> <ul> <li>Chronic over-provisioning driven by guesswork, peak-based sizing, and fear of CPU throttling or OOM crashes</li> <li>Cost inefficiency that node-level bin packing as provided by autoscalers (Cluster Autoscaler/Karpenter) alone cannot fix</li> <li>Operational Load arising from manual tuning of workloads on Kubernetes by developers or DevOps teams</li> </ul> <p>CruiseKube explicitly addresses the pod-level right-sizing problem, in a fully hands-off manner.</p>"},{"location":"blog/2026/01/12/introducing-cruisekube---runtime-resource-optimization-for-kubernetes/#how-does-it-work","title":"How does it work?","text":"<p>At a high level, CruiseKube has the following components -</p> <ul> <li>Statistics Engine: Fetches real-time CPU and memory usage at pod and node level from Prometheus and stores them in a database</li> <li>Runtime Optimizer: Continuously optimizes pod-level resources for running pods across the cluster. It leverages the statistics generated by the statistics engine to generate recommendations per pod</li> <li>Admission Optimizer: Intercepts new pod creations and optimizes the resources of the pod before it is scheduled. This provides a safety net to ensure that the pod is scheduled on a node with sufficient capacity.</li> </ul> <p>Together, these components allow CruiseKube to take ownership of the resource assignment process for pods, ensuring that the pods are always running with the optimal resources.</p>"},{"location":"blog/2026/01/12/introducing-cruisekube---runtime-resource-optimization-for-kubernetes/#why-is-it-different","title":"Why is it different?","text":"<p>CruiseKube is different from other resource optimization tools in the following ways -</p> <ul> <li>Changes are done at pod-level, rather than workload level, thus avoiding the need to restart pods</li> <li>Utilizes PSI adjusted usage to take CPU contention into account for CPU optimization</li> <li>Takes OOM into account for memory optimization and reacts to OOM kills in real-time to improve reliability</li> <li>Optimizes across pods on the same node by sharing resources between all pods, thus improving the node level resource utilization</li> <li>Provides an interface to the user to configure priorities and other controls for the optimization process</li> </ul>"},{"location":"blog/2026/01/12/introducing-cruisekube---runtime-resource-optimization-for-kubernetes/#getting-started","title":"Getting Started","text":"<p>Getting started with CruiseKube is as simple as installing the <code>cruisekube</code> helm chart with appropriate values. Please follow the installation guide to get started.</p>"},{"location":"blog/2026/01/12/introducing-cruisekube---runtime-resource-optimization-for-kubernetes/#whats-next","title":"What's next?","text":"<p>By open-sourcing CruiseKube, we are pushing the boundaries of what is possible with Kubernetes resource optimization. Do get involved in the community by joining our Discord server and sharing your feedback and ideas.</p> <p>Please provide your feedback and ideas on the GitHub Discussions page or by opening an issue on the GitHub Issues page.</p>"},{"location":"src/arch-algorithm/","title":"Algorithm","text":""},{"location":"src/arch-algorithm/#introduction","title":"Introduction","text":"<p>Resource optimization in Kubernetes can be broken down into two fundamental problems:</p> <ol> <li>Pod-level resource requests: Correctly specifying resource requests for each pod to match actual usage patterns</li> <li>Bin-packing: Efficiently scheduling multiple pods across nodes to maximize utilization</li> </ol> <p>While node auto-provisioners like Karpenter and Cluster Autoscaler address the second problem, they often produce suboptimal results due to reliability constraints like topology spread constraints, affinity rules, and pod disruption budgets. CruiseKube focuses exclusively on the first problem optimizing pod-level resource requests since this is where most resource wastage occurs (industry-wide CPU and memory utilization of provisioned resources is typically very low).</p>"},{"location":"src/arch-algorithm/#problem-context","title":"Problem Context","text":""},{"location":"src/arch-algorithm/#current-state-challenges","title":"Current State Challenges","text":"<p>The current approach to resource management in Kubernetes faces several fundamental challenges:</p> <ul> <li>Reliability over cost: Engineers tend to over-provision resources to avoid reliability issues, prioritizing stability over efficiency</li> <li>Manual configuration: Resource requests must be set manually for each workload, and changes require updating workload definitions (Deployments, StatefulSets, DaemonSets). This adds friction and complexity to resource optimization process.</li> <li>Lopsided workload-level configuration: Pods running on different nodes for the same workload may have different resource requirements. This is particularly bad for DaemonSets where pods on different nodes may have vastly different resource needs - a pod on a large node might need 10x more resources than one on a smaller node, yet all pods share the same resource specification</li> <li>Peak provisioning: CPU usage can spike up to 1000x baseline for workloads with sparse requests or job-like characteristics. Provisioning for these peaks leads to massive cumulative over-provisioning across the cluster</li> </ul>"},{"location":"src/arch-algorithm/#what-changed","title":"What Changed","text":"<p>Two Kubernetes features enable a fundamentally different approach:</p> <ol> <li> <p>Kubernetes 1.33 - Pod-level resource updates:</p> <ul> <li>Resources can now be updated at the pod level without recreating pods</li> <li>Each pod can be optimized independently based on its actual usage patterns</li> <li>Shorter prediction horizons become viable since decisions can be updated near real-time as new data arrives</li> <li>Pods can be optimized considering the current node's conditions, allowing resource sharing between pods on the same node without sacrificing reliability</li> </ul> </li> <li> <p>Kubernetes 1.34 - PSI (Pressure Stall Indicator) metrics:</p> <ul> <li>PSI metrics expose CPU and memory pressure at both node and container levels</li> <li>CPU limits can be removed, replacing PSI metrics for CPU throttling signal for feedback on CPU contention</li> <li>PSI-adjusted CPU usage provides accurate measurements of actual CPU demand under contention</li> </ul> </li> </ol>"},{"location":"src/arch-algorithm/#design-philosophy","title":"Design Philosophy","text":"<p>CruiseKube treats CPU and memory optimization differently:</p> <ul> <li> <p>CPU optimization: Most over-provisioning comes from CPU over-provisioning. Better CPU request specification leads to overall better resource utilization when combined with node auto-provisioners. CPU usage can be extremely spiky, but in case of CPU contention, the workload is throttled rather than failed.</p> </li> <li> <p>Memory optimization: Memory usage tends to be consistent once allocated. Once a container uses a certain amount of memory, it typically remains at that level. However, containers hitting memory limits are immediately killed via OOM (Out-of-Memory), making memory under-provisioning far more dangerous than CPU under-provisioning.</p> </li> </ul>"},{"location":"src/arch-algorithm/#core-concepts","title":"Core Concepts","text":""},{"location":"src/arch-algorithm/#psi-pressure-stall-indicator","title":"PSI (Pressure Stall Indicator)","text":"<p>PSI measures the time a task spends waiting for a resource (CPU, memory, or I/O). For CPU, PSI tracks how long processes wait for CPU time due to contention.</p> <p>PSI-Adjusted CPU Usage Formula:</p> <pre><code>PSI_adjusted_usage = cpu_usage \u00d7 (1 + psi_waiting_rate)\n</code></pre> <p>Where:</p> <ul> <li><code>cpu_usage</code>: Raw CPU usage from <code>container_cpu_usage_seconds_total</code></li> <li><code>psi_waiting_rate</code>: Rate of CPU waiting time from <code>container_pressure_cpu_waiting_seconds_total</code></li> </ul> <p>Example: If a container uses 0.5 CPU cores but experiences 20% CPU waiting time due to contention: <pre><code>PSI_adjusted_usage = 0.5 \u00d7 (1 + 0.2) = 0.6 CPU cores\n</code></pre></p> <p>This adjusted value reflects the actual CPU demand when the container is competing for resources, providing a more accurate basis for resource allocation decisions.</p>"},{"location":"src/arch-algorithm/#steady-state-vs-peak-usage","title":"Steady State vs Peak Usage","text":"<p>CruiseKube distinguishes between two usage patterns:</p> <ul> <li>Steady State (P75): <ul> <li>CPU: The 75th percentile of CPU usage over the last 10 minutes. This represents the current and typical, sustained usage. Thhis serves as the baseline demand. </li> <li>Memory: The 75th percentile of memory usage over the last 30 minutes. The longer window accounts for memory's higher reliability requirements compared to CPU.</li> </ul> </li> <li>Peak Usage (Max): The maximum value observed in the past 60 minutes at the current hour over the last 1 week. This methodology captures recurring patterns (e.g., daily cycles) while accounting for recent spikes. The difference between peak and steady state represents the <code>spike demand</code> or <code>headroom</code> needed to accommodate usage bursts.</li> </ul>"},{"location":"src/arch-algorithm/#algorithm-overview","title":"Algorithm Overview","text":"<p>CruiseKube uses a two-phase optimization approach:</p> <ul> <li> <p>Phase 1 (Admission Webhook): Sets initial resource requests at scheduling time to ensure the pod is scheduled on a node with sufficient capacity.</p> </li> <li> <p>Phase 2 (Continuous Optimization): Periodically optimizes running pods, redistributing resources based on actual node conditions and sharing max headroom across pods.</p> </li> </ul>"},{"location":"src/arch-algorithm/#phase-1-admission-webhook-optimization","title":"Phase 1: Admission Webhook Optimization","text":"<p>The admission webhook intercepts pod creation requests and sets resource requests based on historical usage patterns.</p>"},{"location":"src/arch-algorithm/#when-it-runs","title":"When It Runs","text":"<ul> <li>Triggered during pod creation (before scheduling)</li> <li>Mutates the pod specification before it reaches the scheduler</li> </ul>"},{"location":"src/arch-algorithm/#algorithm","title":"Algorithm","text":"<pre><code>// Fetch historical statistics for this workload/container\nstats = fetchWorkloadStats(pod.workloadIdentifier, container.name)\n\n// Max = max observed in past 60 minutes at current hour over last 1 week\ncpuPeakDemand = stats.CPUStats.Max\nmemoryPeakDemand = stats.MemoryStats.Max\n\n// Set pod requests to accommodate peak usage\npod.spec.containers[container].resources.requests.cpu = cpuPeakDemand\npod.spec.containers[container].resources.requests.memory = memoryPeakDemand\n\n// Set memory limit to 2 \u00d7 max memory over last 7 days (safety buffer)\nmemoryLimit = 2 \u00d7 max(stats.Memory7Day.Max)\npod.spec.containers[container].resources.limits.memory = memoryLimit\n\n// Note: CPU limits are not set (relying on PSI metrics for feedback)\npod.Spec.containers[container].Resources.Limits.CPU = nil\n</code></pre>"},{"location":"src/arch-algorithm/#purpose","title":"Purpose","text":"<ul> <li>Prevents repeated evictions: By setting requests to peak usage, the pod is guaranteed to fit on the node where it's scheduled even after continuous optimization has run.</li> <li>Provides initial optimization: Even without continuous optimization, pods start with better resource allocation</li> </ul>"},{"location":"src/arch-algorithm/#phase-2-continuous-optimization","title":"Phase 2: Continuous Optimization","text":"<p>The continuous optimization controller runs periodically, optimizing resources for pods already running on nodes.</p>"},{"location":"src/arch-algorithm/#when-it-runs_1","title":"When It Runs","text":"<ul> <li>Periodic reconciliation loop (configurable schedule)</li> <li>Processes one node at a time</li> <li>Updates pod resources in-place without pod recreation</li> </ul>"},{"location":"src/arch-algorithm/#algorithm-flow","title":"Algorithm Flow","text":"<pre><code>flowchart TD\n    A[Start: Process Node] --&gt; B[Identify Optimizable Pods]\n    B --&gt; C[Calculate Base + Headroom Demand per Pod]\n    C --&gt; D{Memory Fits?}\n    D --&gt;|No| E[Evict Low Priority Pods&lt;br/&gt;Memory]\n    D --&gt;|Yes| F{CPU Fits?}\n    E --&gt; F\n    F --&gt;|No| G[Evict Low Priority Pods&lt;br/&gt;CPU]\n    F --&gt;|Yes| H[Calculate Max Headroom Demand]\n    G --&gt; H\n    H --&gt; I[Distribute Max Headroom&lt;br/&gt;Proportionally]\n    I --&gt; J[Apply Resource Updates]\n    J --&gt; K[Next Node]</code></pre>"},{"location":"src/arch-algorithm/#detailed-algorithm","title":"Detailed Algorithm","text":"<pre><code>FOR EACH node IN cluster:\n\n  // Step 1: Identify scope of optimization\n  optimizablePods = selectPodsEligibleForOptimization(node.pods)\n  nonOptimizablePods = node.pods - optimizablePods\n\n  availableCPU = node.allocatable.cpu - sum(nonOptimizablePods.cpuRequests)\n  availableMemory = node.allocatable.memory - sum(nonOptimizablePods.memoryRequests)\n\n  // Step 2: Compute baseline demand and headroom demand per pod\n  FOR EACH pod IN optimizablePods:\n    FOR EACH container IN pod.containers:\n      // CPU base demand: P75 over last 10 minutes\n      stats = fetchWorkloadStats(pod.workloadIdentifier, container.name)\n      container.CPUBaseDemand = stats.CPUStats.P75\n\n      // CPU headroom demand: Max - Base\n      container.CPUHeadroomDemand = stats.CPUStats.Max - container.CPUBaseDemand\n\n      // Memory base demand: P75 over last 30 minutes\n      container.MemoryBaseDemand = stats.MemoryStats.P75  // P75 over last 30 min\n\n      // Memory headroom demand: Max - Base\n      container.MemoryHeadroomDemand = stats.MemoryStats.Max - container.MemoryBaseDemand\n\n    pod.evictionRanking = determineEvictionRanking(pod)\n    pod.totalRecommendedCPU = sum(container.CPUBaseDemand)\n    pod.totalRecommendedMemory = sum(container.MemoryBaseDemand)\n    pod.maxHeadroomCPU = max(container.CPUHeadroomDemand)\n    pod.maxHeadroomMemory = max(container.MemoryHeadroomDemand)\n\n  // Step 3: Evict pods if memory doesn't fit\n  sort pods by: DaemonSet &gt; evictionRanking &gt; maxHeadroomMemory (descending)\n  WHILE sum(pod.totalRecommendedMemory) + max(pod.maxHeadroomMemory) &gt; availableMemory:\n    podToEvict = pods[0]  // Lowest priority\n    markForEviction(podToEvict)\n    remove podToEvict from pods\n\n  // Step 4: Evict pods if CPU doesn't fit\n  sort pods by: DaemonSet &gt; evictionRanking &gt; maxHeadroomCPU (descending)\n  WHILE sum(pod.totalRecommendedCPU) + max(pod.maxHeadroomCPU) &gt; availableCPU:\n    podToEvict = pods[0]  // Lowest priority\n    markForEviction(podToEvict)\n    remove podToEvict from pods\n\n  // Step 5: Distribute spike headroom across surviving pods\n  maxHeadroomCPU = max(pod.maxHeadroomCPU for pod IN pods)\n  maxHeadroomMemory = max(pod.maxHeadroomMemory for pod IN pods)\n  totalHeadroomCPU = sum(container.CPUHeadroomDemand for all containers in pods)\n  totalHeadroomMemory = sum(container.MemoryHeadroomDemand for all containers in pods)\n\n  FOR EACH pod IN pods:\n    FOR EACH container IN pod.containers:\n      // Proportional distribution based on each container's spike demand\n      cpuRatio = container.CPUHeadroomDemand / totalHeadroomCPU\n      additionalCPU = maxHeadroomCPU \u00d7 cpuRatio\n\n      memoryRatio = container.MemoryHeadroomDemand / totalHeadroomMemory\n      additionalMemory = maxHeadroomMemory \u00d7 memoryRatio\n\n      container.finalCPU = container.CPUBaseDemand + additionalCPU\n      container.finalMemory = container.MemoryBaseDemand + additionalMemory\n\n  // Step 6: Apply recommendations at runtime\n  FOR EACH pod IN pods:\n    FOR EACH container IN pod.containers:\n      // Apply CPU request (no CPU limit set)\n      applyCPURequest(pod, container, container.finalCPU)\n\n      // Apply memory request and limit\n      // Limit = 2 \u00d7 max(memory over last 7 days, OOM memory)\n      memoryLimit = 2 \u00d7 max(container.stats.Memory7Day.Max)\n      applyMemoryRequestAndLimit(pod, container, container.finalMemory, memoryLimit)\n\nEND\n</code></pre>"},{"location":"src/arch-algorithm/#key-differences-from-admission-webhook","title":"Key Differences from Admission Webhook","text":"<ul> <li>Resource sharing: Headroom is distributed proportionally rather than allocated fully to each pod</li> <li>Node-aware: Considers actual node capacity and current pod placement</li> <li>Eviction support: Can evict pods to make room for better optimization</li> <li>Incremental updates: Resources are updated in-place without pod recreation</li> </ul>"},{"location":"src/arch-algorithm/#key-mechanisms","title":"Key Mechanisms","text":""},{"location":"src/arch-algorithm/#headroom-demand-distribution","title":"Headroom Demand Distribution","text":"<p>Rather than provisioning each pod for its maximum spike, CruiseKube distributes spike headroom across pods on a node. This is done with the following rationale:</p> <ol> <li>Not all pods on a node spike simultaneously</li> <li>The maximum headroom demand across all pods on a node represents the short lived and worst-case scenario for the node</li> </ol> <p>This <code>headroom</code> (i.e. peak usage - steady state) is shared proportionally, reducing total resource requirements for the node</p>"},{"location":"src/arch-algorithm/#eviction-priority","title":"Eviction Priority","text":"<p>When a node cannot accommodate all pods, CruiseKube uses a priority-based eviction system to make space:</p> <ol> <li>DaemonSets: Always protected from eviction (they must run on every node)</li> <li>Eviction Ranking: Configurable per-workload priority that determines eviction order:<ul> <li>Low: Low priority workloads are evicted first. This is the priority for most workloads by default</li> <li>Medium: Medium priority workloads are evicted next. Single replica or statefulset workloads are set to this value by default</li> <li>High: High priority workloads are evicted as a last resort</li> <li>No-Eviction: No-eviction workloads are never evicted at all</li> </ul> </li> <li>Tie-breaker: Among pods with the same eviction ranking, those with higher headroom demand (<code>peak_usage - base_demand</code>) are evicted first, to minimise the number of evictions needed</li> </ol>"},{"location":"src/arch-algorithm/#memory-limit-calculation","title":"Memory Limit Calculation","text":"<p>Memory limits are set independently from memory requests to provide a safety buffer:</p> <ul> <li>Memory Limit Formula: <code>2 \u00d7 (maxMemoryUsage7Days, limitMemoryAtOOMKill)</code></li> <li><code>maxMemoryUsage7Days</code>: Maximum memory usage observed over the last 7 days</li> <li><code>limitMemoryAtOOMKill</code>: Memory limit at the time of OOM kill events (if any)</li> <li>Purpose: Prevents OOM kills by providing headroom above the optimized request value</li> <li>Rationale: Memory requests can be optimized aggressively (down to P75 + distributed spike), while limits ensure containers have sufficient headroom to handle unexpected memory growth</li> </ul>"},{"location":"src/arch-algorithm/#why-cpu-limits-arent-needed","title":"Why CPU Limits Aren't Needed","text":"<p>CruiseKube does not set CPU limits, only CPU requests. This differs from memory, where both requests and limits are configured.</p> <p>Traditional CPU limits serve two purposes:</p> <ol> <li>Resource isolation: Prevent one pod from consuming all CPU</li> <li>Throttling feedback: Indicate when a pod needs more CPU</li> </ol> <p>With PSI metrics:</p> <ul> <li>PSI provides throttling feedback: High PSI values indicate CPU contention without needing limits</li> <li>Requests provide isolation: CPU requests ensure fair scheduling and resource allocation</li> <li>Better observability: PSI metrics provide more granular insight into contention than throttling metrics</li> </ul> <p>Contrast with Memory:</p> <p>By removing CPU limits and using PSI-adjusted usage for requests, CruiseKube:</p> <ul> <li>Eliminates unnecessary CPU throttling</li> <li>Provides more accurate CPU resource allocation</li> <li>Maintains reliability through PSI-based feedback</li> <li>Allows CPU to burst when available, improving overall utilization</li> </ul>"},{"location":"src/arch-algorithm/#safety-reliability-related-mechanisms","title":"Safety &amp; Reliability Related Mechanisms","text":""},{"location":"src/arch-algorithm/#node-load-monitoring","title":"Node Load Monitoring","text":"<p>To mitigate scenarios where multiple pods spike simultaneously, CruiseKube monitors node load:</p> <ul> <li>Load Calculation: <code>node_load1 / node_cpu_capacity</code></li> <li>Threshold: When load exceeds 100% (1.0), the node is considered overloaded</li> <li>Action: Node is cordoned (tainted with <code>NoSchedule</code>) to prevent new pod scheduling</li> <li>Recovery: Taint is removed when load drops below threshold</li> </ul> <p>During overload:</p> <ul> <li>PSI metrics increase, causing future resource requests to be higher</li> <li>No new pods are scheduled on the overloaded node to prevent further resource contention</li> </ul>"},{"location":"src/arch-algorithm/#preventing-repeated-evictions","title":"Preventing Repeated Evictions","text":"<p>The admission webhook ensures pods are scheduled with requests equal to their peak usage. This guarantees:</p> <ul> <li>The node has sufficient capacity at scheduling time</li> <li>Subsequent continuous optimization runs only evict pods whose spikes cannot be accommodated</li> <li>Once evicted, a pod will be rescheduled with peak requests, preventing immediate re-eviction</li> </ul>"},{"location":"src/arch-algorithm/#high-priority-workload-protection","title":"High-Priority Workload Protection","text":"<ul> <li>Single-replica workloads and StatefulSets default to medium eviction ranking</li> <li>Most workloads default to low eviction ranking</li> <li>Users can configure eviction ranking per workload via overrides</li> <li>DaemonSets are never evicted</li> <li>Workloads with no-eviction ranking are never evicted</li> </ul>"},{"location":"src/arch-algorithm/#contention-mitigation","title":"Contention Mitigation","text":"<ul> <li>Node cordoning: Overloaded nodes are isolated to prevent further scheduling</li> <li>PSI feedback: High PSI values increase resource requests for future optimizations</li> <li>Proportional distribution: Headroom is shared, reducing the likelihood of simultaneous spikes exhausting resources</li> </ul>"},{"location":"src/arch-algorithm/#references","title":"References","text":"<ul> <li>Kubernetes 1.33 - Pod-level resource updates</li> <li>Kubernetes 1.34 - PSI (Pressure Stall Indicator) metrics</li> <li>PSI Documentation</li> </ul>"},{"location":"src/arch-overview/","title":"Overview","text":""},{"location":"src/arch-overview/#overview","title":"Overview","text":"<p>CruiseKube operates as a closed-loop system through a set of periodic background tasks. Each task has a clearly defined responsibility and can be enabled or disabled independently.</p> <ol> <li>Create Stats Task: Builds persistent, workload-level CPU and memory statistics from Kubernetes state and Prometheus metrics. These stats form the foundation for all optimization decisions and are stored for reuse.</li> <li>Apply Recommendation Task: Generates and applies CPU and memory recommendations to workloads in a controlled, incremental manner. This is the core task responsible for actually right-sizing workloads.</li> <li>Fetch Metrics Task: Fetches metrics from the cluster and exposes them as prometheus metrics.</li> <li>Node Load Monitoring Task: Monitors the CPU load on nodes and isolates nodes that are overloaded.</li> </ol> <p>Together, these tasks allow CruiseKube to continuously optimize resources without relying on manual tuning or reactive scaling.</p>"},{"location":"src/arch-overview/#components","title":"Components","text":"<pre><code>flowchart LR\n    %% Actor\n    Human((Human))\n\n    %% Kubernetes Cluster Boundary\n    subgraph K8s[Kubernetes Cluster]\n        direction LR\n\n        %% Frontend\n        Frontend[Frontend]\n\n        %% Controller\n        subgraph Controller\n            direction TB\n            Stats[Statistics Engine]\n            Runtime[Runtime Optimizer]\n        end\n\n        %% API Server\n        APIServer[kube-api-server]\n\n        %% Webhook\n        subgraph Webhook\n            Admission[Admission Optimizer]\n        end\n\n        %% Data &amp; Metrics\n        Database[(Database)]\n        Prometheus[Prometheus]\n    end\n\n    %% User Flow\n    Human --&gt; Frontend\n    Frontend --&gt; Controller\n\n    %% Control Plane Flow\n    Controller --&gt; APIServer\n    APIServer &lt;--&gt; Webhook\n\n    %% Data Flow\n    Controller --&gt; Database\n    Webhook --&gt; Database\n    Controller --&gt; Prometheus</code></pre> <p>The high-level architecture consists of 4 components deployed using the CruiseKube Helm chart:</p> <ul> <li>Controller<ul> <li>Statistics Engine - Collects metrics from the cluster and stores them in the database</li> <li>Runtime Optimizer - Optimizes the resources of the running workloads on the cluster</li> </ul> </li> <li>Webhook<ul> <li>Admission Optimizer - Intercepts new pod creations and optimizes the resources of the pod before it is scheduled</li> </ul> </li> <li>Frontend<ul> <li>Observable interface for recommendations - The frontend provides a user-friendly interface to view the recommendations and the potential savings</li> <li>Setting User configurations per workload - The frontend allows the user to set the user configurations like priority, mode, etc. per workload</li> <li>Potential savings once CruiseKube is enabled in Cruise mode - The frontend shows the potential savings once CruiseKube is enabled in Cruise mode</li> </ul> </li> <li>Database:<ul> <li>Stores the statistics generated by the Statistics Engine - The database stores the statistics generated by the Statistics Engine</li> <li>Stores the user configurations per workload - The database stores the user configurations like priority, mode, etc. per workload</li> </ul> </li> </ul>"},{"location":"src/arch-overview/#statistics-engine","title":"Statistics Engine","text":"<ul> <li>Continuously evaluates CPU and memory usage for each workload</li> <li>Track instances of high CPU load and memory OOMs</li> <li>Derives stable statistics (percentiles, headroom, variability)</li> <li>Persists computed metrics in an internal datastore</li> <li>Built on Prometheus as the primary metrics source</li> </ul>"},{"location":"src/arch-overview/#runtime-optimizer","title":"Runtime Optimizer","text":"<ul> <li>Implemented as a reconciliation loop in <code>cruisekube-controller</code></li> <li>Iteratively optimizes running workloads, one node at a time</li> <li>Keeps the priority of individual workloads into account to minimise disruption</li> </ul>"},{"location":"src/arch-overview/#admission-optimizer","title":"Admission Optimizer","text":"<ul> <li>Implemented as a mutating admission webhook</li> <li>Intercepts new pod creations</li> <li>Rewrites resource requests using learned recommendations</li> </ul>"},{"location":"src/arch-overview/#control-flows","title":"Control Flows","text":""},{"location":"src/arch-overview/#statistics-engine_1","title":"Statistics Engine","text":"<pre><code>sequenceDiagram\n  %% CruiseKube Statistics Engine \u2013 Metrics Collection &amp; Feature Building\n\n  participant P as Prometheus\n  participant T as Statistics Engine\n  participant S as Kubernetes API Server\n  participant DB as Database\n\n  loop Every scrape/aggregation interval\n    T-&gt;&gt;S: List Pods, Nodes (metadata)\n    T-&gt;&gt;P: Query metrics (usage, throttling, pressure)\n    T-&gt;&gt;T: Calculate stats per namespace/workload/container\n    T-&gt;&gt;T: Compute aggregates (e.g., percentiles, peaks, trends)\n    T-&gt;&gt;DB: Persist container stats\n  end\n</code></pre> <ol> <li>Connects to target cluster prometheus and cluster</li> <li>Calculates stats related to CPU usage, CPU pressure, memory usage, OOM instances etc.</li> <li>Stores the calculated statistics into database</li> </ol>"},{"location":"src/arch-overview/#runtime-optimizer-flow","title":"Runtime Optimizer Flow","text":"<pre><code>sequenceDiagram\n  %% CruiseKube Core Loop (simplified)\n  participant C as CruiseKube Controller\n  participant M as Database\n%%   participant N as Node\n  participant K as Kube API\n\n  loop Every reconcile interval\n    C-&gt;&gt;M: Read usage + pressure signals (per pod/container)\n    C-&gt;&gt;K: Read node allocatable + pod placement\n    %% C-&gt;&gt;C: Partition pods (optimizable vs reserved)\n    C-&gt;&gt;C: Estimate StableDemand + SpikeDemand (PSI-adjusted if available)\n    alt Fits within node capacity\n      C-&gt;&gt;C: Distribute SpikeDemand amongst pods\n      C-&gt;&gt;K: Patch pod resources in-place\n    else Not feasible\n      C-&gt;&gt;C: Choose eviction candidates by priority\n      C-&gt;&gt;K: Evict pods until feasible\n      C-&gt;&gt;C: Distribute SpikeDemand amongst pods\n      C-&gt;&gt;K: Patch pod resources in-place\n    end\n  end</code></pre> <ol> <li>Connect to target cluster to iterate over nodes</li> <li>Fetch workload statistics from DB</li> <li>Adjusts resources in-place for pods on the node</li> </ol>"},{"location":"src/arch-overview/#admission-optimizer-flow","title":"Admission Optimizer Flow","text":"<pre><code>sequenceDiagram\n  %% CruiseKube Admission Webhook \u2013 Scheduling-Time Optimization\n\n  participant U as User / Controller\n  participant K as Kubernetes API Server\n  participant W as CruiseKube Mutating Webhook\n  participant M as Database\n%%   participant S as Scheduler\n%%   participant N as Node\n\n  U-&gt;&gt;K: Create Pod\n  K-&gt;&gt;W: AdmissionReview (PodSpec)\n  W-&gt;&gt;M: Fetch historical usage(for workload / container)\n  W-&gt;&gt;W: Estimate StableDemand + SpikeDemand\n  W-&gt;&gt;W: Compute initial pod requests = Stable + Spike\n  W--&gt;&gt;K: Mutated PodSpec (updated requests/limits)\n%%   K-&gt;&gt;S: Schedule Pod\n%%   S-&gt;&gt;N: Bind Pod to Node\n%%   N--&gt;&gt;K: Pod running\n</code></pre> <ol> <li>Intercept pod spec</li> <li>Fetch statistics from the controller</li> <li>Mutate requests before scheduling</li> </ol>"},{"location":"src/arch-overview/#next-steps","title":"Next Steps","text":"<ul> <li>Get started with installation here</li> </ul>"},{"location":"src/comp/","title":"Comp","text":""},{"location":"src/comp/#cruisekube-vs-kubernetes-vertical-pod-autoscaler-vpa","title":"CruiseKube vs Kubernetes Vertical Pod Autoscaler (VPA)","text":"<p>Both CruiseKube Autopilot and Kubernetes VPA aim to right-size workloads\u2014but they are built for very different operating models.</p>"},{"location":"src/comp/#the-core-difference","title":"The Core Difference","text":"<p>VPA is a recommendation engine. Autopilot is a runtime optimization system.</p>"},{"location":"src/comp/#how-they-differ","title":"How They Differ","text":"Dimension CruiseKube Autopilot Kubernetes Vertical Pod Autoscaler Optimization mode Continuous, runtime Periodic, restart-based Pod restarts required \u274c No \u2705 Yes (for apply) Decision granularity Per-pod, per-node Per-workload Time horizon Short-term, adaptive Long-term, historical CPU handling Dynamic, PSI-aware, burst-friendly Static recommendations Memory handling Conservative, OOM-aware Risky if misapplied Node awareness \u2705 Yes (shared headroom) \u274c No Eviction strategy Priority-aware, safety-first None FinOps alignment Strong (waste-focused) Limited"},{"location":"src/comp/#why-vpa-falls-short-in-practice","title":"Why VPA Falls Short in Practice","text":"<ul> <li> <p>Restart dependency   Applying VPA recommendations requires pod restarts, making it unsuitable for frequent or fine-grained adjustments.</p> </li> <li> <p>Workload-level abstraction   VPA treats all replicas of a workload identically, ignoring node-specific conditions and skewed resource usage.</p> </li> <li> <p>Static safety bias   VPA recommendations are intentionally conservative, often preserving over-provisioning rather than eliminating it.</p> </li> </ul>"},{"location":"src/comp/#what-autopilot-unlocks","title":"What Autopilot Unlocks","text":"<ul> <li> <p>True runtime right-sizing   Autopilot updates CPU and memory requests in place, without restarts, enabling near-real-time correction.</p> </li> <li> <p>Node-local intelligence   Decisions account for colocated pods and available node headroom, not isolated workload averages.</p> </li> <li> <p>CPU burst efficiency without risk   PSI-aware feedback allows safe CPU overcommit without throttling-induced reliability issues.</p> </li> <li> <p>Eviction as a controlled safety valve   When capacity limits are reached, Autopilot enforces stability via priority-aware evictions\u2014never blind pressure.</p> </li> </ul>"},{"location":"src/comp/#when-to-use-which","title":"When to Use Which","text":"<ul> <li> <p>Use VPA if</p> <ul> <li>You want occasional, coarse recommendations</li> <li>Pod restarts are acceptable</li> <li>Cost optimization is secondary to simplicity</li> </ul> </li> <li> <p>Use CruiseKube Autopilot if</p> <ul> <li>You want continuous cost and efficiency gains</li> <li>Restarts are unacceptable</li> <li>You operate multi-tenant or high-utilization clusters</li> <li>FinOps outcomes matter</li> </ul> </li> </ul>"},{"location":"src/config-dashboard/","title":"Configuration Dashboard","text":"<p>The CruiseKube dashboard provides a web interface for monitoring and managing your resource optimization settings.</p>"},{"location":"src/config-dashboard/#accessing-the-dashboard","title":"Accessing the Dashboard","text":"<p>The dashboard is exposed as a Kubernetes Service and can be accessed in several ways:</p>"},{"location":"src/config-dashboard/#using-kubectl-port-forward","title":"Using kubectl port-forward","text":"<pre><code>kubectl port-forward -n cruisekube-system svc/cruisekube-frontend 3000:3000\n</code></pre>"},{"location":"src/config-dashboard/#using-ingress-if-configured","title":"Using ingress (if configured)","text":"<p>If you have configured an ingress controller and exposed the dashboard via ingress, you can access it using the configured domain.</p>"},{"location":"src/config-dashboard/#workload-recommendation","title":"Workload &amp; Recommendation","text":"<p>You can view the recommendations and manage workloads through the dashboard. This tells you the current status, optimization suggestions and cost saved for your workloads.</p> <p></p> <p></p>"},{"location":"src/config-dashboard/#policies-configuration","title":"Policies &amp; Configuration","text":"<p>You can configure optimization policies and settings for your workloads through the dashboard.</p> <p></p>"},{"location":"src/config-dashboard/#configure-options-for-workloads","title":"Configure Options For Workloads","text":"<ol> <li>Recomment Mode (Disabled): No optimization is applied to the workload.</li> <li>Cruise Mode (Enabled): CruiseKube applies optimization to the workload based on the configured policies.</li> <li>Priority: We use a notion of per-workload priority to make sure the lower priority workloads are evicted first if possible. Workloads with single replica or part of a statefulset are kept at a higher priority by default.<ul> <li>Low: Low priority workloads are evicted first. This is the priority for most workloads by default</li> <li>Medium: Medium priority workloads are evicted next. Single replica or statefulset workloads are set to this value by default</li> <li>High: High priority workloads are evicted as a last resort</li> <li>No-Eviction: No-eviction workloads are never evicted at all</li> </ul> </li> </ol>"},{"location":"src/config/","title":"Configuration","text":"<p>You can refer to the Helm values documentation for configuration options.</p>"},{"location":"src/dev-contributors/","title":"CruiseKube Contributors - Open Source Community","text":"<p>This page recognizes all the dedicated and incredible people who have contributed to the CruiseKube project. We appreciate all contributions, from code to documentation, testing, and community support.</p> <p></p> <p>Loading contributors...</p>"},{"location":"src/dev-env/","title":"Development Environment","text":"<p>This page describes how to set up and work with the CruiseKube development environment.</p>"},{"location":"src/dev-env/#1-get-required-tools","title":"1. Get required tools","text":"<p>Ensure you have the following tools installed:</p> <ul> <li>Go 1.21 or later</li> <li>Docker</li> <li>Kubernetes cluster (minikube or kind recommended for local development)</li> <li>Kubectl</li> <li>Helm </li> <li>Kind</li> <li>Make </li> </ul>"},{"location":"src/dev-env/#2-clone-the-repository","title":"2. Clone the repository","text":"<p>Clone the CruiseKube repository from GitHub:</p> <pre><code>git clone https://github.com/truefoundry/cruiseKube.git\ncd cruiseKube\n</code></pre> <p>Make sure you check out the documentation and architecture before making your changes.</p>"},{"location":"src/dev-env/#3-build-images","title":"3. Build images","text":"<p>To build the CruiseKube images, run:</p> <pre><code>docker build -t cruisekube:latest .\n</code></pre>"},{"location":"src/dev-env/#4-start-kind-cluster","title":"4. Start Kind cluster","text":"<p>First, create a Kind cluster:</p> <pre><code>kind create cluster --name cruisekube --config=test/kind-config.yaml\n</code></pre> <p>Then load the built image into the cluster:</p> <pre><code>kind load docker-image cruisekube:latest --name cruisekube\n</code></pre>"},{"location":"src/dev-env/#5-install-prometheus","title":"5. Install Prometheus","text":"<p>To install Prometheus, run:</p> <pre><code>helm repo add prometheus-community https://prometheus-community.github.io/helm-charts\nhelm repo update\nhelm upgrade --install prometheus \\\n        prometheus-community/kube-prometheus-stack \\\n        --namespace monitoring \\\n        --create-namespace \\\n        --set prometheus.service.type=NodePort \\\n        --set prometheus.service.nodePort=30090 \\\n        --set prometheus.prometheusSpec.serviceMonitorSelectorNilUsesHelmValues=false \\\n        --set prometheus.prometheusSpec.podMonitorSelectorNilUsesHelmValues=false \\\n        --set prometheus.prometheusSpec.ruleSelectorNilUsesHelmValues=false \\\n        --set grafana.enabled=false \\\n        --set alertmanager.enabled=false \\\n        --set kubeStateMetrics.enabled=true \\\n        --set nodeExporter.enabled=true \\\n        --set prometheusOperator.enabled=true \\\n        --wait --timeout=600s\n</code></pre>"},{"location":"src/dev-env/#6-install-cruisekube","title":"6. Install CruiseKube","text":"<p>To install CruiseKube, run:</p> <pre><code>helm upgrade --install cruisekube \\\n    ./charts/cruisekube \\\n    --namespace cruisekube \\\n    --create-namespace \\\n    --set cruisekubeController.image.repository=cruisekube \\\n    --set cruisekubeController.image.tag=latest \\\n    --set cruisekubeController.image.pullPolicy=Never \\\n    --set cruisekubeController.env.CRUISEKUBE_DEPENDENCIES_INCLUSTER_PROMETHEUSURL=\"http://prometheus-kube-prometheus-prometheus.monitoring.svc:9090\" \\\n    --set cruisekubeController.env.CRUISEKUBE_CONTROLLER_TASKS_CREATESTATS_ENABLED=true \\\n    --set cruisekubeWebhook.image.repository=cruisekube \\\n    --set cruisekubeWebhook.image.tag=latest \\\n    --set cruisekubeWebhook.image.pullPolicy=Never \\\n    --set cruisekubeWebhook.webhook.statsURL.host=\"https://localhost:8080\" \\\n    --set postgresql.enabled=true \\\n    --set cruisekubeFrontend.enabled=false \\\n    --wait --timeout=60s\n</code></pre> <p>Note: We have disabled the frontend for local development to simplify the setup.</p> <p>To redeploy your changes after making code modifications, simply rebuild the image and reload it into the cluster:</p> <pre><code>docker build -t cruisekube:latest .\nkind load docker-image cruisekube:latest --name cruisekube\n</code></pre> <p>Then restart the CruiseKube controller:</p> <pre><code>kubectl rollout restart deployment/cruisekube-controller -n cruisekube\nkubectl rollout restart deployment/cruisekube-webhook -n cruisekube\n</code></pre>"},{"location":"src/dev-env/#8-delete-the-deployment","title":"8. Delete the deployment","text":"<p>To delete the CruiseKube deployment, run:</p> <pre><code>helm uninstall cruisekube -n cruisekube\n</code></pre>"},{"location":"src/gs-installation/","title":"Setup","text":"<p>Get started by following below steps:</p>"},{"location":"src/gs-installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Kubernetes Cluster: You should have a running Kubernetes cluster with at least Kubernetes 1.33. You can use any cloud-based or on-premises Kubernetes distribution.</li> <li>kubectl: Installed and configured to interact with your Kubernetes cluster.</li> <li>Helm: Installed for managing Kubernetes applications.</li> <li>Prometheus: You should have a prometheus installed in your cluster.</li> </ul> Installing Prometheus <p>We will setup a sample prometheus to read metrics from the ingress controller.</p> <pre><code>helm repo add prometheus-community https://prometheus-community.github.io/helm-charts\nhelm repo update\nhelm install kube-prometheus-stack prometheus-community/kube-prometheus-stack \\\n  --namespace monitoring \\\n  --create-namespace \\\n  --set alertmanager.enabled=false \\\n  --set grafana.enabled=false \\\n  --set prometheus.prometheusSpec.serviceMonitorSelectorNilUsesHelmValues=false\n</code></pre>"},{"location":"src/gs-installation/#install","title":"Install","text":""},{"location":"src/gs-installation/#1-install-cruisekube-using-helm","title":"1. Install CruiseKube using helm","text":"<p>Install CruiseKube from the OCI registry:</p> <pre><code>helm install ck-demo oci://tfy.jfrog.io/tfy-helm/cruisekube --namespace cruisekube-system --create-namespace\n</code></pre> <p>Note: You can customize the installation by providing your own <code>values.yaml</code> file with specific configurations. See the configuration documentation for available options.</p> <p></p>"},{"location":"src/gs-installation/#2-verify-installation","title":"2. Verify Installation","text":"<p>Check that the CruiseKube components are running:</p> <pre><code>kubectl get pods -n cruisekube-system\n</code></pre> <p>You should see pods like <code>cruisekube-controller-manager-xxx</code> and <code>cruisekube-webhook-server-xxx</code> in the <code>Running</code> state.</p> <p></p>"},{"location":"src/gs-installation/#3-enable-tasks","title":"3. Enable Tasks","text":"<p>By default, all tasks are disabled. This is to prevent any unintended optimizations.  You will need to manually enable each task based on your requirements. To do this, you will need to pass environment variables in the values file to the Helm chart.</p> <ol> <li> <p>Enable Create Stats Task</p> <ul> <li>To enable this task, set the <code>CRUISEKUBE_CONTROLLER_TASKS_CREATESTATS_ENABLED</code> environment variable to <code>true</code> in your values file.</li> <li>You also need to configure prometheus URL in the env section of the values file. This will be used by the stats creation task to fetch metrics. Set <code>CRUISEKUBE_DEPENDENCIES_INCLUSTER_PROMETHEUSURL</code> to the URL of your Prometheus instance.</li> </ul> </li> <li> <p>Enable Apply Recommendation Task</p> <ul> <li>To enable this task, set the <code>CRUISEKUBE_CONTROLLER_TASKS_APPLYRECOMMENDATION_ENABLED</code> environment variable to <code>true</code> in your values file. Note this is currently in dry-run mode by default. So recommendations will only be generated but not applied.</li> </ul> </li> </ol> <p>Similarly, you can enable other tasks by checking the available environment variables in the value.yaml file.</p> <p></p>"},{"location":"src/gs-installation/#4-view-recommendations","title":"4. View Recommendations","text":"<p>Once the tasks are enabled, you can view the recommendations generated by Port-Forwarding the frontend service.</p> <pre><code>kubectl port-forward -n cruisekube-system svc/cruisekube-frontend 3000:3000\n</code></pre> <p>Open your browser and navigate to <code>http://localhost:3000</code> to view the recommendations.</p> <p></p> <p>Read more about configuration in the Configuration Dashboard section.</p> <p></p>"},{"location":"src/gs-installation/#5-apply-recommendations","title":"5. Apply Recommendations","text":"<p>Once you've reviewed the recommendations in the dashboard, you can disable the dry-run mode to actually apply the recommendations. </p> <p>To enable the apply recommendation task, set the <code>CRUISEKUBE_CONTROLLER_TASKS_APPLYRECOMMENDATION_DRYRUN</code> environment variable to <code>false</code> in your values file.</p>"},{"location":"src/gs-installation/#uninstall","title":"Uninstall","text":"<p>To uninstall CruiseKube, run:</p> <pre><code>helm uninstall ck-demo -n cruisekube-system\nkubectl delete namespace cruisekube-system\n</code></pre>"},{"location":"src/gs-introduction/","title":"Introduction","text":""},{"location":"src/gs-introduction/#what-is-cruisekube","title":"What is CruiseKube?","text":"<p>CruiseKube is a Kubernetes-native, continuous resource optimization system that autonomously right-sizes CPU and memory for workloads at runtime and admission time. It focuses on eliminating persistent over-provisioning while preserving workload reliability and scheduling constraints.</p> <p>Unlike static requests, manual tuning, or reactive autoscaling, CruiseKube operates as a closed-loop control system that observes real workload behavior and incrementally converges resource requests toward optimal values.</p>"},{"location":"src/gs-introduction/#when-do-you-need-cruisekube","title":"When do you need CruiseKube?","text":"<p>You would need CruiseKube if you are facing any of these issues -</p> <ul> <li>Chronic over-provisioning driven by guesswork, peak-based sizing, and fear of CPU throttling or OOM crashes</li> <li>Cost inefficiency that node-level bin packing as provided by autoscalers (Cluster Autoscaler/Karpenter) alone cannot fix</li> <li>Operational Load arising from manual tuning of workloads on kubernetes by developers or DevOps teams</li> </ul> <p>CruiseKube explicitly addresses the pod-level right-sizing problem, in a fully hands-off manner.</p>"},{"location":"src/gs-introduction/#architecture","title":"Architecture","text":"<pre><code>flowchart LR\n    %% Actor\n    Human((Human))\n\n    %% Kubernetes Cluster Boundary\n    subgraph K8s[Kubernetes Cluster]\n        direction LR\n\n        %% Frontend\n        Frontend[Frontend]\n\n        %% Controller\n        subgraph Controller\n            direction TB\n            Stats[Statistics Engine]\n            Runtime[Runtime Optimizer]\n        end\n\n        %% API Server\n        APIServer[kube-api-server]\n\n        %% Webhook\n        subgraph Webhook\n            Admission[Admission Optimizer]\n        end\n\n        %% Data &amp; Metrics\n        Database[(Database)]\n        Prometheus[Prometheus]\n    end\n\n    %% User Flow\n    Human --&gt; Frontend\n    Frontend --&gt; Controller\n\n    %% Control Plane Flow\n    Controller --&gt; APIServer\n    APIServer &lt;--&gt; Webhook\n\n    %% Data Flow\n    Controller --&gt; Database\n    Webhook --&gt; Database\n    Controller --&gt; Prometheus</code></pre> <p>Read more about the architecture in the Architecture section.</p>"},{"location":"blog/archive/2026/","title":"2026","text":""}]}